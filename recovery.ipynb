{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/definiter/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "import tensorflow as tf\n",
    "\n",
    "tflib.init_tf()\n",
    "url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
    "    _G, _D, Gs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'recovery_scope/target_image:0' shape=(1024, 1024, 3) dtype=float32_ref>\n",
      "Tensor(\"ExpandDims:0\", shape=(1, 1024, 1024, 3), dtype=float32)\n",
      "<tf.Variable 'recovery_scope/learnable_latents:0' shape=(1, 512) dtype=float32_ref>\n",
      "Tensor(\"Gs_1/images_out:0\", shape=(1, 3, 1024, 1024), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(1, 1024, 1024, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /home/definiter/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /home/definiter/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "<tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7fd26c79abe0>\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_recovery_scope/learnable_latents/ApplyGradientDescent\"\n",
      "\n",
      "-------\n",
      "0\n",
      "Loss:  11389.93\n",
      "-------\n",
      "1\n",
      "Loss:  4418.748\n",
      "-------\n",
      "2\n",
      "Loss:  3400.1702\n",
      "-------\n",
      "3\n",
      "Loss:  3318.0762\n",
      "-------\n",
      "4\n",
      "Loss:  3404.1287\n",
      "-------\n",
      "5\n",
      "Loss:  5238.261\n",
      "-------\n",
      "6\n",
      "Loss:  10704.226\n",
      "-------\n",
      "7\n",
      "Loss:  14634.177\n",
      "-------\n",
      "8\n",
      "Loss:  4497.3535\n",
      "-------\n",
      "9\n",
      "Loss:  2984.5986\n",
      "-------\n",
      "10\n",
      "Loss:  2802.1045\n",
      "-------\n",
      "11\n",
      "Loss:  2666.787\n",
      "-------\n",
      "12\n",
      "Loss:  2583.7456\n",
      "-------\n",
      "13\n",
      "Loss:  2462.9126\n",
      "-------\n",
      "14\n",
      "Loss:  2350.949\n",
      "-------\n",
      "15\n",
      "Loss:  2277.5964\n",
      "-------\n",
      "16\n",
      "Loss:  2180.8145\n",
      "-------\n",
      "17\n",
      "Loss:  2123.7979\n",
      "-------\n",
      "18\n",
      "Loss:  2047.8939\n",
      "-------\n",
      "19\n",
      "Loss:  2005.4498\n",
      "-------\n",
      "20\n",
      "Loss:  1945.6631\n",
      "-------\n",
      "21\n",
      "Loss:  1898.9686\n",
      "-------\n",
      "22\n",
      "Loss:  1858.0153\n",
      "-------\n",
      "23\n",
      "Loss:  1820.3561\n",
      "-------\n",
      "24\n",
      "Loss:  1785.6392\n",
      "-------\n",
      "25\n",
      "Loss:  1751.0665\n",
      "-------\n",
      "26\n",
      "Loss:  1714.1595\n",
      "-------\n",
      "27\n",
      "Loss:  1685.1361\n",
      "-------\n",
      "28\n",
      "Loss:  1654.1132\n",
      "-------\n",
      "29\n",
      "Loss:  1627.4951\n",
      "-------\n",
      "30\n",
      "Loss:  1583.9696\n",
      "-------\n",
      "31\n",
      "Loss:  1553.3671\n",
      "-------\n",
      "32\n",
      "Loss:  1516.7955\n",
      "-------\n",
      "33\n",
      "Loss:  1485.0342\n",
      "-------\n",
      "34\n",
      "Loss:  1456.603\n",
      "-------\n",
      "35\n",
      "Loss:  1433.2609\n",
      "-------\n",
      "36\n",
      "Loss:  1408.4927\n",
      "-------\n",
      "37\n",
      "Loss:  1388.046\n",
      "-------\n",
      "38\n",
      "Loss:  1369.2041\n",
      "-------\n",
      "39\n",
      "Loss:  1352.4806\n",
      "-------\n",
      "40\n",
      "Loss:  1337.2948\n",
      "-------\n",
      "41\n",
      "Loss:  1323.5522\n",
      "-------\n",
      "42\n",
      "Loss:  1310.13\n",
      "-------\n",
      "43\n",
      "Loss:  1297.3386\n",
      "-------\n",
      "44\n",
      "Loss:  1283.7675\n",
      "-------\n",
      "45\n",
      "Loss:  1271.046\n",
      "-------\n",
      "46\n",
      "Loss:  1257.6857\n",
      "-------\n",
      "47\n",
      "Loss:  1244.557\n",
      "-------\n",
      "48\n",
      "Loss:  1232.334\n",
      "-------\n",
      "49\n",
      "Loss:  1222.3905\n",
      "-------\n",
      "50\n",
      "Loss:  1213.3075\n",
      "-------\n",
      "51\n",
      "Loss:  1204.8805\n",
      "-------\n",
      "52\n",
      "Loss:  1197.7367\n",
      "-------\n",
      "53\n",
      "Loss:  1191.1902\n",
      "-------\n",
      "54\n",
      "Loss:  1184.269\n",
      "-------\n",
      "55\n",
      "Loss:  1177.6178\n",
      "-------\n",
      "56\n",
      "Loss:  1171.7137\n",
      "-------\n",
      "57\n",
      "Loss:  1165.4567\n",
      "-------\n",
      "58\n",
      "Loss:  1159.619\n",
      "-------\n",
      "59\n",
      "Loss:  1154.2135\n",
      "-------\n",
      "60\n",
      "Loss:  1149.4038\n",
      "-------\n",
      "61\n",
      "Loss:  1144.8871\n",
      "-------\n",
      "62\n",
      "Loss:  1141.0092\n",
      "-------\n",
      "63\n",
      "Loss:  1136.5532\n",
      "-------\n",
      "64\n",
      "Loss:  1132.3483\n",
      "-------\n",
      "65\n",
      "Loss:  1127.7227\n",
      "-------\n",
      "66\n",
      "Loss:  1123.6206\n",
      "-------\n",
      "67\n",
      "Loss:  1119.4861\n",
      "-------\n",
      "68\n",
      "Loss:  1115.3823\n",
      "-------\n",
      "69\n",
      "Loss:  1111.7125\n",
      "-------\n",
      "70\n",
      "Loss:  1108.1862\n",
      "-------\n",
      "71\n",
      "Loss:  1104.5089\n",
      "-------\n",
      "72\n",
      "Loss:  1101.0538\n",
      "-------\n",
      "73\n",
      "Loss:  1097.5428\n",
      "-------\n",
      "74\n",
      "Loss:  1095.2306\n",
      "-------\n",
      "75\n",
      "Loss:  1093.4722\n",
      "-------\n",
      "76\n",
      "Loss:  1091.7528\n",
      "-------\n",
      "77\n",
      "Loss:  1090.8884\n",
      "-------\n",
      "78\n",
      "Loss:  1093.5448\n",
      "-------\n",
      "79\n",
      "Loss:  1093.7804\n",
      "-------\n",
      "80\n",
      "Loss:  1096.769\n",
      "-------\n",
      "81\n",
      "Loss:  1093.299\n",
      "-------\n",
      "82\n",
      "Loss:  1091.5184\n",
      "-------\n",
      "83\n",
      "Loss:  1085.6621\n",
      "-------\n",
      "84\n",
      "Loss:  1081.4076\n",
      "-------\n",
      "85\n",
      "Loss:  1075.0013\n",
      "-------\n",
      "86\n",
      "Loss:  1073.1465\n",
      "-------\n",
      "87\n",
      "Loss:  1067.7963\n",
      "-------\n",
      "88\n",
      "Loss:  1067.3334\n",
      "-------\n",
      "89\n",
      "Loss:  1065.7723\n",
      "-------\n",
      "90\n",
      "Loss:  1066.9359\n",
      "-------\n",
      "91\n",
      "Loss:  1065.5065\n",
      "-------\n",
      "92\n",
      "Loss:  1063.5203\n",
      "-------\n",
      "93\n",
      "Loss:  1060.2832\n",
      "-------\n",
      "94\n",
      "Loss:  1057.6451\n",
      "-------\n",
      "95\n",
      "Loss:  1054.5272\n",
      "-------\n",
      "96\n",
      "Loss:  1050.2334\n",
      "-------\n",
      "97\n",
      "Loss:  1046.0021\n",
      "-------\n",
      "98\n",
      "Loss:  1044.1469\n",
      "-------\n",
      "99\n",
      "Loss:  1042.819\n",
      "-------\n",
      "100\n",
      "Loss:  1040.6282\n",
      "-------\n",
      "101\n",
      "Loss:  1040.3087\n",
      "-------\n",
      "102\n",
      "Loss:  1039.4967\n",
      "-------\n",
      "103\n",
      "Loss:  1037.4813\n",
      "-------\n",
      "104\n",
      "Loss:  1034.5817\n",
      "-------\n",
      "105\n",
      "Loss:  1033.0494\n",
      "-------\n",
      "106\n",
      "Loss:  1030.6626\n",
      "-------\n",
      "107\n",
      "Loss:  1029.347\n",
      "-------\n",
      "108\n",
      "Loss:  1026.5989\n",
      "-------\n",
      "109\n",
      "Loss:  1025.1031\n",
      "-------\n",
      "110\n",
      "Loss:  1022.76807\n",
      "-------\n",
      "111\n",
      "Loss:  1021.11273\n",
      "-------\n",
      "112\n",
      "Loss:  1019.23456\n",
      "-------\n",
      "113\n",
      "Loss:  1017.60846\n",
      "-------\n",
      "114\n",
      "Loss:  1016.0418\n",
      "-------\n",
      "115\n",
      "Loss:  1014.69464\n",
      "-------\n",
      "116\n",
      "Loss:  1013.31836\n",
      "-------\n",
      "117\n",
      "Loss:  1012.02094\n",
      "-------\n",
      "118\n",
      "Loss:  1010.73175\n",
      "-------\n",
      "119\n",
      "Loss:  1009.3913\n",
      "-------\n",
      "120\n",
      "Loss:  1008.1785\n",
      "-------\n",
      "121\n",
      "Loss:  1007.00977\n",
      "-------\n",
      "122\n",
      "Loss:  1006.2527\n",
      "-------\n",
      "123\n",
      "Loss:  1005.2128\n",
      "-------\n",
      "124\n",
      "Loss:  1004.1921\n",
      "-------\n",
      "125\n",
      "Loss:  1003.03754\n",
      "-------\n",
      "126\n",
      "Loss:  1001.8376\n",
      "-------\n",
      "127\n",
      "Loss:  1000.6643\n",
      "-------\n",
      "128\n",
      "Loss:  999.424\n",
      "-------\n",
      "129\n",
      "Loss:  998.22015\n",
      "-------\n",
      "130\n",
      "Loss:  997.19653\n",
      "-------\n",
      "131\n",
      "Loss:  996.1514\n",
      "-------\n",
      "132\n",
      "Loss:  995.17725\n",
      "-------\n",
      "133\n",
      "Loss:  994.11005\n",
      "-------\n",
      "134\n",
      "Loss:  993.0596\n",
      "-------\n",
      "135\n",
      "Loss:  992.1785\n",
      "-------\n",
      "136\n",
      "Loss:  991.0684\n",
      "-------\n",
      "137\n",
      "Loss:  990.0938\n",
      "-------\n",
      "138\n",
      "Loss:  989.272\n",
      "-------\n",
      "139\n",
      "Loss:  988.9512\n",
      "-------\n",
      "140\n",
      "Loss:  987.987\n",
      "-------\n",
      "141\n",
      "Loss:  987.03613\n",
      "-------\n",
      "142\n",
      "Loss:  986.6097\n",
      "-------\n",
      "143\n",
      "Loss:  985.8132\n",
      "-------\n",
      "144\n",
      "Loss:  986.072\n",
      "-------\n",
      "145\n",
      "Loss:  984.8127\n",
      "-------\n",
      "146\n",
      "Loss:  984.75195\n",
      "-------\n",
      "147\n",
      "Loss:  983.92975\n",
      "-------\n",
      "148\n",
      "Loss:  983.428\n",
      "-------\n",
      "149\n",
      "Loss:  983.09174\n",
      "-------\n",
      "150\n",
      "Loss:  982.75635\n",
      "-------\n",
      "151\n",
      "Loss:  981.55273\n",
      "-------\n",
      "152\n",
      "Loss:  980.66895\n",
      "-------\n",
      "153\n",
      "Loss:  979.56146\n",
      "-------\n",
      "154\n",
      "Loss:  979.28815\n",
      "-------\n",
      "155\n",
      "Loss:  978.59204\n",
      "-------\n",
      "156\n",
      "Loss:  978.0203\n",
      "-------\n",
      "157\n",
      "Loss:  976.6545\n",
      "-------\n",
      "158\n",
      "Loss:  976.02826\n",
      "-------\n",
      "159\n",
      "Loss:  975.29047\n",
      "-------\n",
      "160\n",
      "Loss:  974.73413\n",
      "-------\n",
      "161\n",
      "Loss:  973.5925\n",
      "-------\n",
      "162\n",
      "Loss:  972.9482\n",
      "-------\n",
      "163\n",
      "Loss:  972.0643\n",
      "-------\n",
      "164\n",
      "Loss:  971.5301\n",
      "-------\n",
      "165\n",
      "Loss:  970.74316\n",
      "-------\n",
      "166\n",
      "Loss:  970.6613\n",
      "-------\n",
      "167\n",
      "Loss:  970.27264\n",
      "-------\n",
      "168\n",
      "Loss:  968.96686\n",
      "-------\n",
      "169\n",
      "Loss:  968.3891\n",
      "-------\n",
      "170\n",
      "Loss:  968.27325\n",
      "-------\n",
      "171\n",
      "Loss:  967.95636\n",
      "-------\n",
      "172\n",
      "Loss:  966.679\n",
      "-------\n",
      "173\n",
      "Loss:  966.2253\n",
      "-------\n",
      "174\n",
      "Loss:  965.3755\n",
      "-------\n",
      "175\n",
      "Loss:  965.2031\n",
      "-------\n",
      "176\n",
      "Loss:  964.7464\n",
      "-------\n",
      "177\n",
      "Loss:  964.5507\n",
      "-------\n",
      "178\n",
      "Loss:  963.7525\n",
      "-------\n",
      "179\n",
      "Loss:  963.6276\n",
      "-------\n",
      "180\n",
      "Loss:  962.9058\n",
      "-------\n",
      "181\n",
      "Loss:  962.7083\n",
      "-------\n",
      "182\n",
      "Loss:  962.4175\n",
      "-------\n",
      "183\n",
      "Loss:  962.43555\n",
      "-------\n",
      "184\n",
      "Loss:  961.99365\n",
      "-------\n",
      "185\n",
      "Loss:  962.15375\n",
      "-------\n",
      "186\n",
      "Loss:  961.2526\n",
      "-------\n",
      "187\n",
      "Loss:  960.43475\n",
      "-------\n",
      "188\n",
      "Loss:  959.6528\n",
      "-------\n",
      "189\n",
      "Loss:  959.3106\n",
      "-------\n",
      "190\n",
      "Loss:  958.499\n",
      "-------\n",
      "191\n",
      "Loss:  958.02045\n",
      "-------\n",
      "192\n",
      "Loss:  957.16376\n",
      "-------\n",
      "193\n",
      "Loss:  956.73724\n",
      "-------\n",
      "194\n",
      "Loss:  956.3965\n",
      "-------\n",
      "195\n",
      "Loss:  956.0196\n",
      "-------\n",
      "196\n",
      "Loss:  955.40533\n",
      "-------\n",
      "197\n",
      "Loss:  954.9915\n",
      "-------\n",
      "198\n",
      "Loss:  954.4588\n",
      "-------\n",
      "199\n",
      "Loss:  954.0467\n",
      "-------\n",
      "200\n",
      "Loss:  953.7585\n",
      "-------\n",
      "201\n",
      "Loss:  953.3623\n",
      "-------\n",
      "202\n",
      "Loss:  952.9971\n",
      "-------\n",
      "203\n",
      "Loss:  952.7249\n",
      "-------\n",
      "204\n",
      "Loss:  952.41766\n",
      "-------\n",
      "205\n",
      "Loss:  952.292\n",
      "-------\n",
      "206\n",
      "Loss:  952.01953\n",
      "-------\n",
      "207\n",
      "Loss:  951.5469\n",
      "-------\n",
      "208\n",
      "Loss:  951.10034\n",
      "-------\n",
      "209\n",
      "Loss:  950.774\n",
      "-------\n",
      "210\n",
      "Loss:  950.5964\n",
      "-------\n",
      "211\n",
      "Loss:  950.5241\n",
      "-------\n",
      "212\n",
      "Loss:  950.5048\n",
      "-------\n",
      "213\n",
      "Loss:  950.2676\n",
      "-------\n",
      "214\n",
      "Loss:  949.38696\n",
      "-------\n",
      "215\n",
      "Loss:  949.0071\n",
      "-------\n",
      "216\n",
      "Loss:  948.77246\n",
      "-------\n",
      "217\n",
      "Loss:  948.3957\n",
      "-------\n",
      "218\n",
      "Loss:  948.1714\n",
      "-------\n",
      "219\n",
      "Loss:  948.14795\n",
      "-------\n",
      "220\n",
      "Loss:  948.5525\n",
      "-------\n",
      "221\n",
      "Loss:  948.0262\n",
      "-------\n",
      "222\n",
      "Loss:  947.7619\n",
      "-------\n",
      "223\n",
      "Loss:  947.7375\n",
      "-------\n",
      "224\n",
      "Loss:  947.9405\n",
      "-------\n",
      "225\n",
      "Loss:  947.2585\n",
      "-------\n",
      "226\n",
      "Loss:  947.27386\n",
      "-------\n",
      "227\n",
      "Loss:  946.82306\n",
      "-------\n",
      "228\n",
      "Loss:  946.7544\n",
      "-------\n",
      "229\n",
      "Loss:  946.25635\n",
      "-------\n",
      "230\n",
      "Loss:  946.08014\n",
      "-------\n",
      "231\n",
      "Loss:  945.62866\n",
      "-------\n",
      "232\n",
      "Loss:  945.4012\n",
      "-------\n",
      "233\n",
      "Loss:  945.314\n",
      "-------\n",
      "234\n",
      "Loss:  945.1517\n",
      "-------\n",
      "235\n",
      "Loss:  944.6696\n",
      "-------\n",
      "236\n",
      "Loss:  944.5262\n",
      "-------\n",
      "237\n",
      "Loss:  944.626\n",
      "-------\n",
      "238\n",
      "Loss:  944.76953\n",
      "-------\n",
      "239\n",
      "Loss:  943.977\n",
      "-------\n",
      "240\n",
      "Loss:  943.9737\n",
      "-------\n",
      "241\n",
      "Loss:  943.55225\n",
      "-------\n",
      "242\n",
      "Loss:  943.91016\n",
      "-------\n",
      "243\n",
      "Loss:  943.06696\n",
      "-------\n",
      "244\n",
      "Loss:  943.2288\n",
      "-------\n",
      "245\n",
      "Loss:  942.4322\n",
      "-------\n",
      "246\n",
      "Loss:  942.3918\n",
      "-------\n",
      "247\n",
      "Loss:  942.3007\n",
      "-------\n",
      "248\n",
      "Loss:  941.8176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "249\n",
      "Loss:  941.7828\n",
      "-------\n",
      "250\n",
      "Loss:  941.3311\n",
      "-------\n",
      "251\n",
      "Loss:  941.1744\n",
      "-------\n",
      "252\n",
      "Loss:  941.1215\n",
      "-------\n",
      "253\n",
      "Loss:  940.85284\n",
      "-------\n",
      "254\n",
      "Loss:  940.81805\n",
      "-------\n",
      "255\n",
      "Loss:  940.8425\n",
      "-------\n",
      "256\n",
      "Loss:  941.31177\n",
      "-------\n",
      "257\n",
      "Loss:  940.37695\n",
      "-------\n",
      "258\n",
      "Loss:  940.6763\n",
      "-------\n",
      "259\n",
      "Loss:  939.9746\n",
      "-------\n",
      "260\n",
      "Loss:  940.0402\n",
      "-------\n",
      "261\n",
      "Loss:  939.4082\n",
      "-------\n",
      "262\n",
      "Loss:  939.6165\n",
      "-------\n",
      "263\n",
      "Loss:  939.0739\n",
      "-------\n",
      "264\n",
      "Loss:  939.9222\n",
      "-------\n",
      "265\n",
      "Loss:  938.99066\n",
      "-------\n",
      "266\n",
      "Loss:  939.0937\n",
      "-------\n",
      "267\n",
      "Loss:  938.4118\n",
      "-------\n",
      "268\n",
      "Loss:  938.6909\n",
      "-------\n",
      "269\n",
      "Loss:  938.09\n",
      "-------\n",
      "270\n",
      "Loss:  938.3732\n",
      "-------\n",
      "271\n",
      "Loss:  937.8863\n",
      "-------\n",
      "272\n",
      "Loss:  937.7695\n",
      "-------\n",
      "273\n",
      "Loss:  937.44354\n",
      "-------\n",
      "274\n",
      "Loss:  937.53375\n",
      "-------\n",
      "275\n",
      "Loss:  936.9048\n",
      "-------\n",
      "276\n",
      "Loss:  937.3842\n",
      "-------\n",
      "277\n",
      "Loss:  936.6622\n",
      "-------\n",
      "278\n",
      "Loss:  936.7175\n",
      "-------\n",
      "279\n",
      "Loss:  936.1169\n",
      "-------\n",
      "280\n",
      "Loss:  936.47876\n",
      "-------\n",
      "281\n",
      "Loss:  936.21893\n",
      "-------\n",
      "282\n",
      "Loss:  936.514\n",
      "-------\n",
      "283\n",
      "Loss:  935.9431\n",
      "-------\n",
      "284\n",
      "Loss:  936.1582\n",
      "-------\n",
      "285\n",
      "Loss:  935.48175\n",
      "-------\n",
      "286\n",
      "Loss:  935.4619\n",
      "-------\n",
      "287\n",
      "Loss:  934.6193\n",
      "-------\n",
      "288\n",
      "Loss:  934.97314\n",
      "-------\n",
      "289\n",
      "Loss:  934.61444\n",
      "-------\n",
      "290\n",
      "Loss:  934.9305\n",
      "-------\n",
      "291\n",
      "Loss:  934.3987\n",
      "-------\n",
      "292\n",
      "Loss:  934.6208\n",
      "-------\n",
      "293\n",
      "Loss:  934.02545\n",
      "-------\n",
      "294\n",
      "Loss:  933.82794\n",
      "-------\n",
      "295\n",
      "Loss:  933.52295\n",
      "-------\n",
      "296\n",
      "Loss:  933.6872\n",
      "-------\n",
      "297\n",
      "Loss:  932.78217\n",
      "-------\n",
      "298\n",
      "Loss:  932.87225\n",
      "-------\n",
      "299\n",
      "Loss:  933.0356\n",
      "-------\n",
      "300\n",
      "Loss:  933.3405\n",
      "-------\n",
      "301\n",
      "Loss:  932.3059\n",
      "-------\n",
      "302\n",
      "Loss:  932.36884\n",
      "-------\n",
      "303\n",
      "Loss:  931.73627\n",
      "-------\n",
      "304\n",
      "Loss:  931.82446\n",
      "-------\n",
      "305\n",
      "Loss:  932.32623\n",
      "-------\n",
      "306\n",
      "Loss:  932.3903\n",
      "-------\n",
      "307\n",
      "Loss:  931.1795\n",
      "-------\n",
      "308\n",
      "Loss:  931.6839\n",
      "-------\n",
      "309\n",
      "Loss:  930.94147\n",
      "-------\n",
      "310\n",
      "Loss:  930.79364\n",
      "-------\n",
      "311\n",
      "Loss:  930.75543\n",
      "-------\n",
      "312\n",
      "Loss:  930.6328\n",
      "-------\n",
      "313\n",
      "Loss:  930.6716\n",
      "-------\n",
      "314\n",
      "Loss:  930.4336\n",
      "-------\n",
      "315\n",
      "Loss:  930.7181\n",
      "-------\n",
      "316\n",
      "Loss:  931.0788\n",
      "-------\n",
      "317\n",
      "Loss:  929.7862\n",
      "-------\n",
      "318\n",
      "Loss:  929.8374\n",
      "-------\n",
      "319\n",
      "Loss:  929.4221\n",
      "-------\n",
      "320\n",
      "Loss:  929.31494\n",
      "-------\n",
      "321\n",
      "Loss:  929.27075\n",
      "-------\n",
      "322\n",
      "Loss:  928.8298\n",
      "-------\n",
      "323\n",
      "Loss:  928.658\n",
      "-------\n",
      "324\n",
      "Loss:  928.9732\n",
      "-------\n",
      "325\n",
      "Loss:  928.7519\n",
      "-------\n",
      "326\n",
      "Loss:  928.66046\n",
      "-------\n",
      "327\n",
      "Loss:  928.8996\n",
      "-------\n",
      "328\n",
      "Loss:  929.14276\n",
      "-------\n",
      "329\n",
      "Loss:  928.17365\n",
      "-------\n",
      "330\n",
      "Loss:  927.72235\n",
      "-------\n",
      "331\n",
      "Loss:  927.396\n",
      "-------\n",
      "332\n",
      "Loss:  927.6116\n",
      "-------\n",
      "333\n",
      "Loss:  927.75165\n",
      "-------\n",
      "334\n",
      "Loss:  927.26587\n",
      "-------\n",
      "335\n",
      "Loss:  927.1701\n",
      "-------\n",
      "336\n",
      "Loss:  927.2085\n",
      "-------\n",
      "337\n",
      "Loss:  927.374\n",
      "-------\n",
      "338\n",
      "Loss:  927.051\n",
      "-------\n",
      "339\n",
      "Loss:  926.875\n",
      "-------\n",
      "340\n",
      "Loss:  926.38165\n",
      "-------\n",
      "341\n",
      "Loss:  926.04865\n",
      "-------\n",
      "342\n",
      "Loss:  926.22675\n",
      "-------\n",
      "343\n",
      "Loss:  926.1961\n",
      "-------\n",
      "344\n",
      "Loss:  926.0203\n",
      "-------\n",
      "345\n",
      "Loss:  925.89667\n",
      "-------\n",
      "346\n",
      "Loss:  925.60254\n",
      "-------\n",
      "347\n",
      "Loss:  925.3242\n",
      "-------\n",
      "348\n",
      "Loss:  925.81836\n",
      "-------\n",
      "349\n",
      "Loss:  925.6706\n",
      "-------\n",
      "350\n",
      "Loss:  925.26685\n",
      "-------\n",
      "351\n",
      "Loss:  925.10547\n",
      "-------\n",
      "352\n",
      "Loss:  924.7502\n",
      "-------\n",
      "353\n",
      "Loss:  924.6455\n",
      "-------\n",
      "354\n",
      "Loss:  924.79425\n",
      "-------\n",
      "355\n",
      "Loss:  924.9175\n",
      "-------\n",
      "356\n",
      "Loss:  924.5721\n",
      "-------\n",
      "357\n",
      "Loss:  924.58966\n",
      "-------\n",
      "358\n",
      "Loss:  924.2234\n",
      "-------\n",
      "359\n",
      "Loss:  924.196\n",
      "-------\n",
      "360\n",
      "Loss:  923.8206\n",
      "-------\n",
      "361\n",
      "Loss:  923.74506\n",
      "-------\n",
      "362\n",
      "Loss:  923.3857\n",
      "-------\n",
      "363\n",
      "Loss:  923.242\n",
      "-------\n",
      "364\n",
      "Loss:  923.35236\n",
      "-------\n",
      "365\n",
      "Loss:  923.28827\n",
      "-------\n",
      "366\n",
      "Loss:  922.94904\n",
      "-------\n",
      "367\n",
      "Loss:  922.80756\n",
      "-------\n",
      "368\n",
      "Loss:  922.5618\n",
      "-------\n",
      "369\n",
      "Loss:  922.4357\n",
      "-------\n",
      "370\n",
      "Loss:  922.5615\n",
      "-------\n",
      "371\n",
      "Loss:  922.5983\n",
      "-------\n",
      "372\n",
      "Loss:  922.2199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b8746fce236e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mz_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted_output_value_uint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted_output_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted_output_variable_uint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted_output_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_path = './results/face.png'\n",
    "image_size = (1024, 1024)\n",
    "learning_rate = 0.001\n",
    "num_iter = 1000\n",
    "\n",
    "# Create target image variable \n",
    "image = PIL.Image.open(image_path)\n",
    "image.resize(image_size, PIL.Image.ANTIALIAS)\n",
    "image = np.array(image, dtype=np.float32)\n",
    "with tf.variable_scope(\"recovery_scope\", reuse=tf.AUTO_REUSE):\n",
    "    target_image_variable = tf.get_variable('target_image', \n",
    "                                            dtype=tf.float32,\n",
    "                                            initializer=tf.constant(image))\n",
    "print(target_image_variable)\n",
    "target_variable = tf.expand_dims(target_image_variable, 0)\n",
    "# target_variable = tflib.convert_images_from_uint8(target_variable, drange=[-1,1], nhwc_to_nchw=True)\n",
    "print(target_variable)\n",
    "\n",
    "# Create initial latent variable \n",
    "# z = tf.Variable(np.random.randn(1, Gs.input_shape[1]), dtype=tf.float32)\n",
    "with tf.variable_scope(\"recovery_scope\", reuse=tf.AUTO_REUSE):\n",
    "    z = tf.get_variable('learnable_latents',\n",
    "                        shape=(1, Gs.input_shape[1]),\n",
    "                        dtype=tf.float32,\n",
    "                        initializer=tf.initializers.random_normal())\n",
    "print(z)\n",
    "\n",
    "# Create output image variable\n",
    "# output_variable = Gs.get_output_for(z, None, is_validation=True, randomize_noise=False)\n",
    "output_variable = Gs.get_output_for(z, None, truncation_psi=0.7, randomize_noise=False)\n",
    "# formatted_output_variable = tflib.convert_images_to_uint8(output_variable, drange=[-1,1], nchw_to_nhwc=True)\n",
    "formatted_output_variable = tflib.convert_images_to_uint8(output_variable, \n",
    "                                                          drange=[-1,1], \n",
    "                                                          nchw_to_nhwc=True, \n",
    "                                                          uint8_cast=False)\n",
    "formatted_output_variable_uint8 = tf.saturate_cast(formatted_output_variable, tf.uint8)\n",
    "\n",
    "\n",
    "print(output_variable)\n",
    "print(formatted_output_variable)\n",
    "\n",
    "# Loss\n",
    "# loss = tf.losses.mean_squared_error(labels=target_variable, predictions=output_variable)\n",
    "loss = tf.losses.mean_squared_error(labels=target_variable, predictions=formatted_output_variable)\n",
    "print(loss)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss, var_list=z)\n",
    "print(optimizer)\n",
    "print(train_op)\n",
    "\n",
    "# Session\n",
    "sess = tf.get_default_session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "sess.run(z.initializer)\n",
    "sess.run(target_image_variable.initializer)\n",
    "formatted_output_value_uint8 = None\n",
    "z_value = None\n",
    "for it in range(num_iter):\n",
    "    _, loss_value, z_value, formatted_output_value_uint8, formatted_output_value, target_value = sess.run((train_op, loss, z, formatted_output_variable_uint8, formatted_output_variable, target_variable))\n",
    "    print(\"-------\")    \n",
    "    print(it)\n",
    "    PIL.Image.fromarray(formatted_output_value_uint8[0], 'RGB').save('./results/recovery/{}.png'.format(it))\n",
    "    print(\"Loss: \", loss_value)\n",
    "#     print(\"formatted_output_value: \", formatted_output_value)\n",
    "#     print(\"target_value: \", target_value)\n",
    "\n",
    "# Save image\n",
    "PIL.Image.fromarray(formatted_output_value_uint8[0], 'RGB').save('./results/recovery.png')\n",
    "np.save(os.path.join('./results/recovery.npy'), z_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A minimum example to run \n",
    "z = tf.Variable(np.random.randn(1, Gs.input_shape[1]), dtype=tf.float32)\n",
    "output_variable = Gs.get_output_for(z, None, truncation_psi=0.7, randomize_noise=False)\n",
    "formatted_output_variable = tflib.convert_images_to_uint8(output_variable, drange=[-1,1], nchw_to_nhwc=True)\n",
    "print(output_variable)\n",
    "sess = tf.get_default_session()\n",
    "in_expr = [z]\n",
    "mb_in = [np.random.randn(1, Gs.input_shape[1])]\n",
    "formmated_output_value = sess.run(formatted_output_variable, feed_dict=dict(zip(in_expr, mb_in)))\n",
    "PIL.Image.fromarray(formmated_output_value[0], 'RGB').save('./results/recovery.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def create_stub(name, batch_size):\n",
    "    return tf.constant(0, dtype='float32', shape=(batch_size, 0))\n",
    "\n",
    "\n",
    "def create_variable_for_generator(name, batch_size):\n",
    "    return tf.get_variable('learnable_dlatents',\n",
    "                           shape=(batch_size, 18, 512),\n",
    "                           dtype='float32',\n",
    "                           initializer=tf.initializers.random_normal())\n",
    "\n",
    "\n",
    "initial_dlatents = np.zeros((1, 18, 512))\n",
    "Gs.components.synthesis.run(initial_dlatents,\n",
    "                               randomize_noise=False, minibatch_size=1,\n",
    "                               custom_inputs=[partial(create_variable_for_generator, batch_size=1),\n",
    "                                              partial(create_stub, batch_size=1)],\n",
    "                               structure='fixed')\n",
    "\n",
    "sess = tf.get_default_session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = tf.global_variables()\n",
    "for v in vs:\n",
    "    print(v)\n",
    "    \n",
    "Gs.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
