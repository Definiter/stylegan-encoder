{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "import tensorflow as tf\n",
    "\n",
    "tflib.init_tf()\n",
    "url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
    "    _G, _D, Gs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_folder = './experiments/aligned_images/'\n",
    "image_name = 'white_man_01.png'\n",
    "image_path = image_folder + image_name\n",
    "output_folder = './experiments/L2_z/'\n",
    "image_size = (1024, 1024)\n",
    "learning_rate = 0.001\n",
    "num_iter = 1000\n",
    "\n",
    "# Create target image variable \n",
    "image = PIL.Image.open(image_path)\n",
    "image.resize(image_size, PIL.Image.ANTIALIAS)\n",
    "image = np.array(image, dtype=np.float32)\n",
    "with tf.variable_scope(\"recovery_scope\", reuse=tf.AUTO_REUSE):\n",
    "    target_image_variable = tf.get_variable('target_image', \n",
    "                                            dtype=tf.float32,\n",
    "                                            initializer=tf.constant(image))\n",
    "print(target_image_variable)\n",
    "target_variable = tf.expand_dims(target_image_variable, 0)\n",
    "# target_variable = tflib.convert_images_from_uint8(target_variable, drange=[-1,1], nhwc_to_nchw=True)\n",
    "print(target_variable)\n",
    "\n",
    "# Create initial latent variable \n",
    "# z = tf.Variable(np.random.randn(1, Gs.input_shape[1]), dtype=tf.float32)\n",
    "with tf.variable_scope(\"recovery_scope\", reuse=tf.AUTO_REUSE):\n",
    "    z = tf.get_variable('learnable_latents',\n",
    "                        shape=(1, Gs.input_shape[1]),\n",
    "                        dtype=tf.float32,\n",
    "                        initializer=tf.initializers.random_normal())\n",
    "print(z)\n",
    "\n",
    "# Create output image variable\n",
    "# output_variable = Gs.get_output_for(z, None, is_validation=True, randomize_noise=False)\n",
    "output_variable = Gs.get_output_for(z, None, truncation_psi=0.7, randomize_noise=False)\n",
    "# formatted_output_variable = tflib.convert_images_to_uint8(output_variable, drange=[-1,1], nchw_to_nhwc=True)\n",
    "formatted_output_variable = tflib.convert_images_to_uint8(output_variable, \n",
    "                                                          drange=[-1,1], \n",
    "                                                          nchw_to_nhwc=True, \n",
    "                                                          uint8_cast=False)\n",
    "formatted_output_variable_uint8 = tf.saturate_cast(formatted_output_variable, tf.uint8)\n",
    "\n",
    "\n",
    "print(output_variable)\n",
    "print(formatted_output_variable)\n",
    "\n",
    "# Loss\n",
    "# loss = tf.losses.mean_squared_error(labels=target_variable, predictions=output_variable)\n",
    "loss = tf.losses.mean_squared_error(labels=target_variable, predictions=formatted_output_variable)\n",
    "print(loss)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss, var_list=z)\n",
    "print(optimizer)\n",
    "print(train_op)\n",
    "\n",
    "# Session\n",
    "sess = tf.get_default_session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "sess.run(z.initializer)\n",
    "sess.run(target_image_variable.initializer)\n",
    "formatted_output_value_uint8 = None\n",
    "z_value = None\n",
    "if not os.path.exists(output_folder + image_name):\n",
    "    os.mkdir(output_folder + image_name)\n",
    "for it in range(num_iter):\n",
    "    _, loss_value, z_value, formatted_output_value_uint8, formatted_output_value, target_value = sess.run((train_op, loss, z, formatted_output_variable_uint8, formatted_output_variable, target_variable))\n",
    "    print(\"-------\")    \n",
    "    print(it)\n",
    "    PIL.Image.fromarray(formatted_output_value_uint8[0], 'RGB').save((output_folder + image_name + '/{}.png').format(it))\n",
    "    print(\"Loss: \", loss_value)\n",
    "#     print(\"formatted_output_value: \", formatted_output_value)\n",
    "#     print(\"target_value: \", target_value)\n",
    "\n",
    "# Save image\n",
    "PIL.Image.fromarray(formatted_output_value_uint8[0], 'RGB').save(output_folder + image_name)\n",
    "np.save(os.path.join('./results/recovery.npy'), z_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A minimum example to run \n",
    "z = tf.Variable(np.random.randn(1, Gs.input_shape[1]), dtype=tf.float32)\n",
    "output_variable = Gs.get_output_for(z, None, truncation_psi=0.7, randomize_noise=False)\n",
    "formatted_output_variable = tflib.convert_images_to_uint8(output_variable, drange=[-1,1], nchw_to_nhwc=True)\n",
    "print(output_variable)\n",
    "sess = tf.get_default_session()\n",
    "in_expr = [z]\n",
    "mb_in = [np.random.randn(1, Gs.input_shape[1])]\n",
    "formmated_output_value = sess.run(formatted_output_variable, feed_dict=dict(zip(in_expr, mb_in)))\n",
    "PIL.Image.fromarray(formmated_output_value[0], 'RGB').save('./results/recovery.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def create_stub(name, batch_size):\n",
    "    return tf.constant(0, dtype='float32', shape=(batch_size, 0))\n",
    "\n",
    "\n",
    "def create_variable_for_generator(name, batch_size):\n",
    "    return tf.get_variable('learnable_dlatents',\n",
    "                           shape=(batch_size, 18, 512),\n",
    "                           dtype='float32',\n",
    "                           initializer=tf.initializers.random_normal())\n",
    "\n",
    "\n",
    "initial_dlatents = np.zeros((1, 18, 512))\n",
    "Gs.components.synthesis.run(initial_dlatents,\n",
    "                               randomize_noise=False, minibatch_size=1,\n",
    "                               custom_inputs=[partial(create_variable_for_generator, batch_size=1),\n",
    "                                              partial(create_stub, batch_size=1)],\n",
    "                               structure='fixed')\n",
    "\n",
    "sess = tf.get_default_session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = tf.global_variables()\n",
    "for v in vs:\n",
    "    print(v)\n",
    "    \n",
    "Gs.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
